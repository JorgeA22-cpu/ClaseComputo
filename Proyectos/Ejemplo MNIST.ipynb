{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfeae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg \n",
    "# Pkg.add(\"Lux\")\n",
    "# Pkg.add(\"MLUtils\")\n",
    "# Pkg.add(\"Optimisers\")\n",
    "# Pkg.add(\"Zygote\")\n",
    "# Pkg.add(\"OneHotArrays\")\n",
    "# Pkg.add(\"Random\") \n",
    "# Pkg.add(\"Statistics\")\n",
    "# Pkg.add(\"Printf\")\n",
    "# Pkg.add(\"Reactant\")\n",
    "# Pkg.add(\"MLDatasets\")\n",
    "# Pkg.add(\"SimpleChains\")\n",
    "\n",
    "using Lux, MLUtils, Optimisers, Zygote, OneHotArrays, Random, Statistics, Printf, Reactant\n",
    "using MLDatasets: MNIST\n",
    "using SimpleChains: SimpleChains\n",
    "\n",
    "Reactant.set_default_backend(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70e2a0",
   "metadata": {},
   "source": [
    "DataLoader(collect.((x_train,y_train)); batchsize, shuffle = true, partial = false) \n",
    "\n",
    "En este caso \n",
    "### DataLoader \n",
    "crea distintos mini_batches de forma eficiente \n",
    "\n",
    "### Shuffle = true \n",
    "mezcla los elementos antes de dividirlos en mini_batches, cada época vuelve a mezclar los datos, por lo que los nuevos mini_batches serán distintos \n",
    "\n",
    "### Partial = true \n",
    "Si el número total de datos, no son divisibles por el tamaño del mini_batch, genera un último mini_batch con el resto de datos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c669f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reactant.set_default_backend(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadmnist(batchsize, train_split)\n",
    "    # Load MNIST\n",
    "    N = parse(Bool, get(ENV, \"CI\", \"false\")) ? 1500 : nothing\n",
    "    dataset = MNIST(; split=:train)\n",
    "    if N !== nothing\n",
    "        imgs = dataset.features[:, :, 1:N]\n",
    "        labels_raw = dataset.targets[1:N]\n",
    "    else\n",
    "        imgs = dataset.features\n",
    "        labels_raw = dataset.targets\n",
    "    end\n",
    "\n",
    "    # Process images into (H, W, C, BS) batches\n",
    "    x_data = Float32.(reshape(imgs, size(imgs, 1), size(imgs, 2), 1, size(imgs, 3)))\n",
    "    y_data = onehotbatch(labels_raw, 0:9)\n",
    "    (x_train, y_train), (x_test, y_test) = splitobs((x_data, y_data); at=train_split)\n",
    "\n",
    "    return (\n",
    "        # Use DataLoader to automatically minibatch and shuffle the data\n",
    "        DataLoader(collect.((x_train, y_train)); batchsize, shuffle=true, partial=false),\n",
    "        # Don't shuffle the test data\n",
    "        DataLoader(collect.((x_test, y_test)); batchsize, shuffle=false, partial=false),\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22a4b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse(Bool, get(ENV, \"CI\", \"false\")) ? 1500 : nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc910ff",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_split = 0.9\n",
    " # Process images into (H, W, C, BS) batches\n",
    "  x_data = Float32.(reshape(imgs, size(imgs, 1), size(imgs, 2), 1, size(imgs, 3)))\n",
    "  y_data = onehotbatch(labels_raw, 0:9)\n",
    "  (x_train, y_train), (x_test, y_test) = splitobs((x_data, y_data); at=train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train\n",
    "#y_train\n",
    "x_data # Me interesa que \n",
    "#y_data\n",
    "\n",
    "# Qué recibe dense? \n",
    "# Hacer una función de my_leaky_relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ae5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_batchsize = 128\n",
    "A1 = DataLoader(collect.((x_train, y_train)); batchsize = my_batchsize, shuffle=true, partial=false)\n",
    "A2 = DataLoader(collect.((x_test, y_test)); batchsize = my_batchsize, shuffle=false, partial=false)\n",
    "A3 = DataLoader(collect.((x_train, y_train)); batchsize = my_batchsize, shuffle=true, partial=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad83d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 == A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 == A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6beb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(; split =:train)\n",
    "imgs = dataset.features\n",
    "labels_raw = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00279b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417497c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotbatch(dataset.targets, 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8071fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lux_model = Chain(\n",
    "    Conv((5, 5), 1 => 6, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Conv((5, 5), 6 => 16, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    FlattenLayer(3),\n",
    "    Chain(Dense(256 => 128, relu), Dense(128 => 84, relu), Dense(84 => 10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a666ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptor = ToSimpleChainsAdaptor((28, 28, 1))\n",
    "simple_chains_model = adaptor(lux_model)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59639a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "const lossfn = CrossEntropyLoss(; logits=Val(true)) # const se usa para decirle a Julia que el tipo de la variable global no va a cambiar: https://docs.julialang.org/en/v1/base/base/#const\n",
    "\n",
    "function accuracy(model, ps, st, dataloader)\n",
    "    total_correct, total = 0, 0\n",
    "    st = Lux.testmode(st)\n",
    "    for (x, y) in dataloader\n",
    "        target_class = onecold(Array(y))\n",
    "        predicted_class = onecold(Array(first(model(x, ps, st))))\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045dae4",
   "metadata": {},
   "source": [
    "### Función para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames(Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3af922",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(model, dev=cpu_device(); rng=Random.default_rng(), kwargs...)\n",
    "    train_dataloader, test_dataloader = dev(loadmnist(128, 0.9))\n",
    "    ps, st = dev(Lux.setup(rng, model)) # se inicializan los parámetros del modelo de forma aleatoria y se cargan en el CPU (dev)\n",
    "\n",
    "    vjp = dev isa ReactantDevice ? AutoEnzyme() : AutoZygote() # Usando Reactant permite compilar el modelo antes de entrenarlo: https://lux.csail.mit.edu/stable/manual/compiling_lux_models#reactant-compilation\n",
    "\n",
    "    train_state = Training.TrainState(model, ps, st, Adam(3.0f-4))\n",
    "\n",
    "    if dev isa ReactantDevice\n",
    "        x_ra = first(test_dataloader)[1]\n",
    "        model_compiled = @compile model(x_ra, ps, Lux.testmode(st)) # Justo aquí es compilado el modelo\n",
    "    else\n",
    "        model_compiled = model\n",
    "    end\n",
    "\n",
    "    ### Lets train the model\n",
    "    nepochs = 10 # Cuantas veces se pasa por todos los datos\n",
    "    tr_acc, te_acc = 0.0, 0.0 # Se inicializan las variables de accuracy\n",
    "    for epoch in 1:nepochs\n",
    "        stime = time()\n",
    "        for (x, y) in train_dataloader\n",
    "            _, _, _, train_state = Training.single_train_step!(\n",
    "                vjp, lossfn, (x, y), train_state\n",
    "            )\n",
    "        end\n",
    "        ttime = time() - stime\n",
    "\n",
    "        tr_acc =\n",
    "            accuracy(\n",
    "                model_compiled, train_state.parameters, train_state.states, train_dataloader\n",
    "            ) * 100\n",
    "        te_acc =\n",
    "            accuracy(\n",
    "                model_compiled, train_state.parameters, train_state.states, test_dataloader\n",
    "            ) * 100\n",
    "\n",
    "        @printf \"[%2d/%2d] \\t Time %.2fs \\t Training Accuracy: %.2f%% \\t Test Accuracy: \\\n",
    "                 %.2f%%\\n\" epoch nepochs ttime tr_acc te_acc\n",
    "    end\n",
    "\n",
    "    return train_state.parameters, train_state.states, tr_acc, te_acc # En el código del tutorial no están las primeras dos variables, lo modifiqué para que nos devuelva los parámetros entrenados.\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2250d18",
   "metadata": {},
   "source": [
    "@doc Training.single_train_step!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc Training.single_train_step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\" # Se necesita al correr la primera vez para bajar los datos de MNIST\n",
    "tr_acc, te_acc = train(lux_model, reactant_device()); # entrenando el modelo en lux, este tarda más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\" # Se necesita al correr la primera vez para bajar los datos de MNIST\n",
    "ps, st, tr_acc, te_acc = train(simple_chains_model); #entrenando el modelo de simple simple_chains_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9a9f1",
   "metadata": {},
   "source": [
    "### Analices cómo están formateando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc28b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(; split=:train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b187a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=cpu_device();\n",
    "train_dataloader, test_dataloader = dev(loadmnist(128, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam|>fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f43b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(train_dataloader)[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = dev(loadmnist(128, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "first(test_dataloader)[2][:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e510aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = cpu_device()\n",
    "train_dataloader, test_dataloader = dev(loadmnist(128, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ee650",
   "metadata": {},
   "source": [
    "### Hagamos predicciones con el modelo ya entrenado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c10c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Plots: plot, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d768033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch from the test dataloader\n",
    "x_batch = first(test_dataloader)[1]\n",
    "\n",
    "# Extract the first sample and reshape it to 28×28×1×1\n",
    "single_sample = x_batch[:, :, :, 25]\n",
    "\n",
    "println(\"Shape of single sample: \", size(single_sample))\n",
    "\n",
    "heatmap(single_sample[:, :, 1], c=:grays, title=\"MNIST Image\", xlabel=\"Width\", ylabel=\"Height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "476393ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
