{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LinearAlgebra\n",
    "using LaTeXStrings\n",
    "using HDF5\n",
    "\n",
    "using Lux, MLUtils, Optimisers, Zygote, OneHotArrays, Random, Statistics, Printf, Reactant\n",
    "using MLDatasets: MNIST\n",
    "using SimpleChains: SimpleChains\n",
    "\n",
    "Reactant.set_default_backend(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myleakyrelu (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myleakyrelu(x) = leakyrelu(x,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "    layer_1 = Dense(100 => 64),         \u001b[90m# 6_464 parameters\u001b[39m\n",
       "    layer_2 = Dense(64 => 32),          \u001b[90m# 2_080 parameters\u001b[39m\n",
       "    layer_3 = Dense(32 => 60, myleakyrelu),  \u001b[90m# 1_980 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: \u001b[39m10_524 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Dense(100,64),\n",
    "    Dense(64,32),\n",
    "    Dense(32,60,myleakyrelu)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((layer_1 = (weight = Float32[0.10132206 0.08544423 … 0.0281519 0.0094746305; -0.16883412 -0.11842565 … -0.023698077 -0.13977826; … ; -0.1218989 -0.1476319 … 0.06677648 -0.032968976; -0.0033177682 0.14450046 … -0.15781347 -0.09850688], bias = Float32[-0.0012892603, 0.081913814, -0.040195454, 0.009533584, -0.06345527, 0.008963501, 0.031884205, 0.09437343, -0.080326185, 0.03542757  …  -0.080849946, 0.020556951, 0.09529473, -0.08661993, 0.035990752, 0.02695943, -0.04871583, -0.066234335, 0.05208137, -0.027281772]), layer_2 = (weight = Float32[-0.08565808 0.14090519 … 0.012926232 -0.03458139; -0.06188915 0.21383046 … -0.08361084 0.15074323; … ; -0.20657997 0.09091467 … 0.21633673 -0.12328162; -0.07226994 0.017682238 … -0.16215292 -0.11847095], bias = Float32[-0.075765476, 0.09344193, -0.09282035, 0.012156114, 0.08641355, 0.112708285, 0.0012278706, 0.110777736, -0.114012524, -0.07838319  …  0.10137366, 0.09105086, -0.06663011, 0.06767945, 0.02267243, -0.07684003, 0.022867814, -0.055182233, 0.105136186, 0.03767085]), layer_3 = (weight = Float32[-0.010435565 0.16947022 … 0.2049251 -0.2957712; -0.11349758 0.1404187 … -0.16270371 0.24069698; … ; -0.30498883 -0.2162031 … -0.03670833 0.23135062; -0.008042172 0.2813863 … 0.023426842 -0.30015996], bias = Float32[-0.16114922, 0.14860786, -0.10497901, 0.02906571, -0.108302355, 0.08873943, -0.0924006, -0.10131167, 0.020474454, 0.17271467  …  -0.008459652, -0.073090054, 0.10097938, -0.08552841, -0.105829954, -0.06373525, -0.057432648, 0.044470996, 0.075469054, -0.14159332])), (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the model parameters and states\n",
    "rng = Random.default_rng()  # Random number generator\n",
    "ps, st = Lux.setup(rng, model)\n",
    "\n",
    "# ps: These are the learnable parameters of your model (like weights and biases in neural networks).\n",
    "# st: This contains the non-learnable states of your model (like the running mean and variance in BatchNorm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60×10 Matrix{Float32}:\n",
       "  0.216925     0.365129    0.550028    …  -0.0163418   0.225447    0.0876324\n",
       " -0.0184894   -0.0644057  -0.0320832      -0.0963397  -0.0264815  -0.0582826\n",
       "  0.836579     0.185419    0.407654        1.00704     0.775397    0.341812\n",
       " -0.00970177   0.360714   -0.0336589       0.24449    -0.0576811   0.507113\n",
       "  0.0701354    0.992828    0.647236        0.339482    0.829097    0.653223\n",
       " -0.0931928   -0.116863   -0.0719385   …  -0.0830875  -0.0688008  -0.0990776\n",
       " -0.105169    -0.160983   -0.17239        -0.105989   -0.115978   -0.121647\n",
       " -0.127627    -0.0906539  -0.109302       -0.083723   -0.106605   -0.119703\n",
       " -0.0335222   -0.0726845  -0.0689177      -0.0541632  -0.0469156  -0.0204456\n",
       "  1.37643      0.933213    0.758217        0.87068     1.24889     0.870646\n",
       "  ⋮                                    ⋱                          \n",
       "  0.0352519    0.268227    0.0444416      -0.0164925  -0.0460499   0.153926\n",
       "  0.500839     0.618161    0.433297        0.50493    -0.0183806   0.18024\n",
       " -0.0512222    0.0164261  -0.0109282      -0.0367181  -0.0942022   0.00810762\n",
       " -0.0216619    0.304612    0.028286        0.215651   -0.0116826  -0.0235373\n",
       " -0.0435893   -0.0430184  -0.00921327  …  -0.0493605  -0.0418558  -0.0351892\n",
       " -0.0503006    0.41701    -0.0228689       0.0115212   0.0698676  -0.0132411\n",
       " -0.0604763   -0.102646   -0.0927212      -0.0765549  -0.124337   -0.109814\n",
       " -0.0458071   -0.0931825  -0.107184       -0.0351816  -0.0861137  -0.0722098\n",
       "  1.10193      0.71477     0.972447        0.515306    0.877567    0.379377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's create a dummy input tensor\n",
    "batch_size = 10  # Example batch size\n",
    "dummy_input = rand(Float32, 100, batch_size)  # A random matrix of size (100, batch_size)\n",
    "\n",
    "# Pass the dummy input through the model\n",
    "output = model(dummy_input, ps, st)\n",
    "\n",
    "output[1]# Let's create a dummy input tensor\n",
    "batch_size = 10  # Example batch size\n",
    "dummy_input = rand(Float32, 100, batch_size)  # A random matrix of size (100, batch_size)\n",
    "\n",
    "# Pass the dummy input through the model\n",
    "output = model(dummy_input, ps, st)\n",
    "\n",
    "output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando los datos para nuestro sistema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Any}:\n",
       " [0.0, 1.0, 0.0]\n",
       " [0.0, 2.0, 0.0]\n",
       " [0.0, 3.0, 0.0]\n",
       " [0.0, 0.0, 1.0]\n",
       " [0.0, 1.0, 1.0]\n",
       " [0.0, 2.0, 1.0]\n",
       " [0.0, 3.0, 1.0]\n",
       " [0.0, 0.0, 2.0]\n",
       " [0.0, 1.0, 2.0]\n",
       " [0.0, 2.0, 2.0]\n",
       " [0.0, 3.0, 2.0]\n",
       " [0.0, 0.0, 3.0]\n",
       " [0.0, 1.0, 3.0]\n",
       " [0.0, 2.0, 3.0]\n",
       " [0.0, 3.0, 3.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 3\n",
    "k=2\n",
    "list=[0:3 for _ in 1:k]\n",
    "test_visual_list = []\n",
    "place= 2\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "test_visual_list\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 Matrix{ComplexF64}:\n",
       "   1.54852+0.0im         -0.253676+0.00109675im  …        0.0+0.0im\n",
       " -0.253676-0.00109675im    0.42735+0.0im                  0.0+0.0im\n",
       "  -1.72699+1.52585im           0.0+0.297693im             0.0+0.0im\n",
       "       0.0-0.0178144im    0.179005-0.413142im             0.0+0.0im\n",
       "       0.0+0.0im               0.0+0.0im                  0.0+0.0178144im\n",
       "       0.0+0.0im               0.0+0.0im         …   0.179005+0.413142im\n",
       "       0.0+0.0im               0.0+0.0im            -0.489486-1.33645im\n",
       "       0.0+0.0im               0.0+0.0im             -1.54852+0.0im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# En esta celda tenemos los operadores locales, podemos generar tantos como nos apetezca, pero realmente con generar \n",
    "#un sólo par de operadores locales, podemos considearar n pares de valores aleatorios para que el Hamiltoniano sea distintos\n",
    "\n",
    "particles = 3 # number of qubits\n",
    "d = 2^particles # dimension of the Hilbert space\n",
    "\n",
    "# Matrices de Pauli, será nuestra base. \n",
    "sigmax = [0 1; 1 0]\n",
    "sigmay = [0 -im; im 0]\n",
    "sigmaz = [1 0; 0 -1]\n",
    "id= [1 0; 0 1] # Matriz identidad\n",
    "\n",
    "Sigma = Dict(0 => id, 1 => sigmax, 2 => sigmay, 3 => sigmaz) #Diccionario para llamar a las matrices de Pauli\n",
    "\n",
    "k = 2 # Número de operadores locales que queremos generar\n",
    "\n",
    "list=[0:3 for _ in 1:k] # Arreglo de tres secuencias de 0 a 3\n",
    "\n",
    "# Generamos una lista de combinaciones de los operador local A1 \n",
    "place = 1 # Se utiliza para interactuar únicamente entre el primer y segundo qubit (1er lugar) \n",
    "test_visual_list = []\n",
    "\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "\n",
    "ArrayA1 = []\n",
    "for i in 1:length(test_visual_list)\n",
    "    if test_visual_list[i][place] != test_visual_list[i][place+1] && sum(test_visual_list[i]) != 0\n",
    "        push!(ArrayA1,test_visual_list[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Generamos una lista de combinaciones del operador local A2\n",
    "place = 2 # Se utiliza para interactuar únicamente entre el segundo y tercero qubit (2do lugar)\n",
    "test_visual_list = [] # Se tiene que volver a definir esta lista como una lista vacía \n",
    "\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "\n",
    "ArrayA2 = []\n",
    "for i in 1:length(test_visual_list)\n",
    "    if test_visual_list[i][place] != test_visual_list[i][place+1] && sum(test_visual_list[i]) != 0\n",
    "        push!(ArrayA2,test_visual_list[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Valores aleatorios \n",
    "c = rand(2,1000)*2 .-1 # Estos son los valores de y, los que queremos predecir, cada columna es un valor de y (contiene dos elementos)\n",
    "\n",
    "xaleatMat1 = rand(1000,length(ArrayA1)).*2 .-1\n",
    "xaleatMat2 = rand(1000,length(ArrayA2)).*2 .-1\n",
    "\n",
    "\n",
    "A1P_list = []  # Un arreglo vacío para almacenar matrices\n",
    "A2P_list = []\n",
    "\n",
    "for i in 1:1000\n",
    "    A1P = zeros(2^particles, 2^particles)\n",
    "    for k in 1:length(ArrayA1)\n",
    "        A1P += xaleatMat1[i, k] * kron([Sigma[ArrayA1[k][j]] for j in eachindex(ArrayA1[1])]...)\n",
    "    end\n",
    "    push!(A1P_list, A1P)  # Guardar la matriz en el arreglo\n",
    "end\n",
    "\n",
    "for i in 1:1000\n",
    "    A2P = zeros(2^particles,2^particles)\n",
    "    for k in 1:length(ArrayA2)\n",
    "        A2P += xaleatMat2[i,k]*kron([Sigma[ArrayA2[k][i]] for i in eachindex(ArrayA2[1])]...)\n",
    "    end\n",
    "    push!(A2P_list, A2P)  # Guardar la matriz en el arreglo\n",
    "end\n",
    "\n",
    "A111 = A1P_list[1] \n",
    "A222 = A2P_list[1] # Es por ello que sólo utilizaremos A111 y A222, un sólo par de operadores locales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda lo que haremos es generar un vector de tuplas con la información (x,y) donde x es un vector   \n",
    "# que contiene los promedios a1 y a2 con el estado 0,1,2,... después el vector y tendrá los valores c1 y c2 \n",
    "# estos valores se repetirán para todos los estados que consideramos del mismo Hamiltoniano,\n",
    "# es decir, tomamos para x la mitad de los estados del sistema\n",
    "\n",
    "n = 1000 # Número de datos que queremos generar \n",
    "\n",
    "# Inicializamos un vector vacío para almacenar las 1000 tuplas \n",
    "Tup = []\n",
    "\n",
    "for k in 1 : n\n",
    "\n",
    "    mat1a1 = zeros(2) # Colocamos un vector de ceros que se va a reiniciar en cada paso \n",
    "\n",
    "    # Formamos el Hamiltoniano\n",
    "    H12 = c[1,k]*A111 + c[2,k]*A222\n",
    "\n",
    "    # Tomamos los vectores propios \n",
    "\n",
    "    vor  = eigen(H12).vectors\n",
    "    adjvor = adjoint(vor)\n",
    "\n",
    "    vor[:,1] # Este es el primer vector propio, los vectores propios con eigen se colocan en columnas \n",
    "    adjvor[1,:] # Este es el primer vector propio para la adjunta (Recordemos es un vector izquierdo [Fila])\n",
    "\n",
    "    # Calculamos el valor esperado de la primera mitad de vectores propios\n",
    "\n",
    "    ExpValA = zeros(ComplexF64, Int((size(vor)[1])/2))\n",
    "    for i in 1:Int((size(vor)[1])/2)\n",
    "        ExpValA[i] = transpose(adjvor[i,:])*A111*vor[:,i]\n",
    "    end\n",
    "\n",
    "    ExpValB = zeros(ComplexF64,Int((size(vor)[1])/2))  # ExpVal2[1] = a21 = \\bra{\\phi1_}A_2\\ket{\\phi_1}\n",
    "    for i in 1:Int((size(vor)[1])/2)\n",
    "        ExpValB[i] = transpose(adjvor[i,:])*A222*vor[:,i]\n",
    "    end\n",
    "\n",
    "    ValsA = real(ExpValA) # Nos interesa únicamente la parte real, la parte imaginaria suele ser error \n",
    "    ValsB = real(ExpValB)\n",
    "    mat1a1[1] = ValsA[1]\n",
    "    mat1a1[2] = ValsA[2]\n",
    "\n",
    "    tk = (mat1a1, c[:,k])\n",
    "    push!(Tup,tk) # Agregar la tupla al vector \n",
    "\n",
    "    ValsCompleto = vcat(ValsA, ValsB) # Por último nuestro vector tendrá la forma de 8x1, para poder agregarlo al batch \n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " -2.6616891144873436\n",
       " -2.6445159340119813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tup[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract inputs (x) and outputs (y) from the tuples\n",
    "x_batch = cat(map(t -> t[1], Tup)...; dims=2)  # Stack inputs along the 4th dimension (batch)\n",
    "y_batch = cat(map(t -> t[2], Tup)...; dims=2)  # Stack outputs along the 2nd dimension (batch)\n",
    "\n",
    "# Check the shapes of the resulting batches\n",
    "println(\"Shape of x_batch: \", size(x_batch))  # Should be (28, 28, 1, batch_size)\n",
    "println(\"Shape of y_batch: \", size(y_batch))  # Should be (10, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
