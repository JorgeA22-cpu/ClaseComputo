{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora buscamos generalizar este problema para un número mayor de qubits.\n",
    "\n",
    "Anteriormente se había realizado para 3 partículas, consideramos el entrenamiento únicamente con el estado base, queda por ver qué ocurre cuando usamos más de un estado, dos, tres, la mitad de estados. \n",
    "\n",
    "Empezaremos el problema primero con 4 partículas para considerar cómo lo generalizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Plots\n",
    "using LaTeXStrings\n",
    "using Lux, MLUtils, Optimisers, Zygote, OneHotArrays, Random, Statistics, Printf, Reactant\n",
    "using MLDatasets: MNIST\n",
    "using SimpleChains: SimpleChains\n",
    "\n",
    "Reactant.set_default_backend(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Matrix} with 4 entries:\n",
       "  0 => [1 0; 0 1]\n",
       "  2 => Complex{Int64}[0+0im 0-1im; 0+1im 0+0im]\n",
       "  3 => [1 0; 0 -1]\n",
       "  1 => [0 1; 1 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 4 # number of qubits\n",
    "d = 2^particles # dimension of the Hilbert space\n",
    "\n",
    "# Matrices de Pauli, será nuestra base. \n",
    "sigmax = [0 1; 1 0]\n",
    "sigmay = [0 -im; im 0]\n",
    "sigmaz = [1 0; 0 -1]\n",
    "id= [1 0; 0 1] # Matriz identidad\n",
    "\n",
    "Sigma = Dict(0 => id, 1 => sigmax, 2 => sigmay, 3 => sigmaz) #Diccionario para llamar a las matrices de Pauli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24-element Vector{Any}:\n",
       " [1.0, 0.0, 0.0, 0.0]\n",
       " [2.0, 0.0, 0.0, 0.0]\n",
       " [3.0, 0.0, 0.0, 0.0]\n",
       " [4.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 1.0, 0.0, 0.0]\n",
       " [1.0, 1.0, 0.0, 0.0]\n",
       " [2.0, 1.0, 0.0, 0.0]\n",
       " [3.0, 1.0, 0.0, 0.0]\n",
       " [4.0, 1.0, 0.0, 0.0]\n",
       " [0.0, 2.0, 0.0, 0.0]\n",
       " ⋮\n",
       " [1.0, 3.0, 0.0, 0.0]\n",
       " [2.0, 3.0, 0.0, 0.0]\n",
       " [3.0, 3.0, 0.0, 0.0]\n",
       " [4.0, 3.0, 0.0, 0.0]\n",
       " [0.0, 4.0, 0.0, 0.0]\n",
       " [1.0, 4.0, 0.0, 0.0]\n",
       " [2.0, 4.0, 0.0, 0.0]\n",
       " [3.0, 4.0, 0.0, 0.0]\n",
       " [4.0, 4.0, 0.0, 0.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 4\n",
    "k=2\n",
    "list=[0:4 for _ in 1:k]\n",
    "test_visual_list = []\n",
    "place = 1\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "test_visual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Any}:\n",
       " [0.0, 1.0, 0.0, 0.0]\n",
       " [0.0, 2.0, 0.0, 0.0]\n",
       " [0.0, 3.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 1.0, 0.0]\n",
       " [0.0, 1.0, 1.0, 0.0]\n",
       " [0.0, 2.0, 1.0, 0.0]\n",
       " [0.0, 3.0, 1.0, 0.0]\n",
       " [0.0, 0.0, 2.0, 0.0]\n",
       " [0.0, 1.0, 2.0, 0.0]\n",
       " [0.0, 2.0, 2.0, 0.0]\n",
       " [0.0, 3.0, 2.0, 0.0]\n",
       " [0.0, 0.0, 3.0, 0.0]\n",
       " [0.0, 1.0, 3.0, 0.0]\n",
       " [0.0, 2.0, 3.0, 0.0]\n",
       " [0.0, 3.0, 3.0, 0.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 4\n",
    "k=2\n",
    "list=[0:3 for _ in 1:k]\n",
    "test_visual_list = []\n",
    "place = 2\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "test_visual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Any}:\n",
       " [0.0, 0.0, 1.0, 0.0]\n",
       " [0.0, 0.0, 2.0, 0.0]\n",
       " [0.0, 0.0, 3.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 1.0]\n",
       " [0.0, 0.0, 1.0, 1.0]\n",
       " [0.0, 0.0, 2.0, 1.0]\n",
       " [0.0, 0.0, 3.0, 1.0]\n",
       " [0.0, 0.0, 0.0, 2.0]\n",
       " [0.0, 0.0, 1.0, 2.0]\n",
       " [0.0, 0.0, 2.0, 2.0]\n",
       " [0.0, 0.0, 3.0, 2.0]\n",
       " [0.0, 0.0, 0.0, 3.0]\n",
       " [0.0, 0.0, 1.0, 3.0]\n",
       " [0.0, 0.0, 2.0, 3.0]\n",
       " [0.0, 0.0, 3.0, 3.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 4\n",
    "k=2\n",
    "list=[0:3 for _ in 1:k]\n",
    "test_visual_list = []\n",
    "place = 3\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "test_visual_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los operadores 2-locales se pueden generalizar trivialmente, pero el interés está en cómo vamos a generar a los operadores (N-1)-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63-element Vector{Any}:\n",
       " [1.0, 0.0, 0.0, 0.0]\n",
       " [2.0, 0.0, 0.0, 0.0]\n",
       " [3.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 1.0, 0.0, 0.0]\n",
       " [1.0, 1.0, 0.0, 0.0]\n",
       " [2.0, 1.0, 0.0, 0.0]\n",
       " [3.0, 1.0, 0.0, 0.0]\n",
       " [0.0, 2.0, 0.0, 0.0]\n",
       " [1.0, 2.0, 0.0, 0.0]\n",
       " [2.0, 2.0, 0.0, 0.0]\n",
       " ⋮\n",
       " [3.0, 1.0, 3.0, 0.0]\n",
       " [0.0, 2.0, 3.0, 0.0]\n",
       " [1.0, 2.0, 3.0, 0.0]\n",
       " [2.0, 2.0, 3.0, 0.0]\n",
       " [3.0, 2.0, 3.0, 0.0]\n",
       " [0.0, 3.0, 3.0, 0.0]\n",
       " [1.0, 3.0, 3.0, 0.0]\n",
       " [2.0, 3.0, 3.0, 0.0]\n",
       " [3.0, 3.0, 3.0, 0.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 4\n",
    "k = 3\n",
    "list=[0:3 for _ in 1:k]\n",
    "ArrayA1 = []\n",
    "place = 1\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(ArrayA1,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "ArrayA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63-element Vector{Any}:\n",
       " [0.0, 1.0, 0.0, 0.0]\n",
       " [0.0, 2.0, 0.0, 0.0]\n",
       " [0.0, 3.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 1.0, 0.0]\n",
       " [0.0, 1.0, 1.0, 0.0]\n",
       " [0.0, 2.0, 1.0, 0.0]\n",
       " [0.0, 3.0, 1.0, 0.0]\n",
       " [0.0, 0.0, 2.0, 0.0]\n",
       " [0.0, 1.0, 2.0, 0.0]\n",
       " [0.0, 2.0, 2.0, 0.0]\n",
       " ⋮\n",
       " [0.0, 3.0, 1.0, 3.0]\n",
       " [0.0, 0.0, 2.0, 3.0]\n",
       " [0.0, 1.0, 2.0, 3.0]\n",
       " [0.0, 2.0, 2.0, 3.0]\n",
       " [0.0, 3.0, 2.0, 3.0]\n",
       " [0.0, 0.0, 3.0, 3.0]\n",
       " [0.0, 1.0, 3.0, 3.0]\n",
       " [0.0, 2.0, 3.0, 3.0]\n",
       " [0.0, 3.0, 3.0, 3.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 4\n",
    "k = 3\n",
    "list=[0:3 for _ in 1:k]\n",
    "ArrayA2 = []\n",
    "place = 2\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(ArrayA2,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "ArrayA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora queremos a cada configuración de matrices de Pauli asociarle un coeficiente aleatorio para cada operador 3-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16×16 Matrix{ComplexF64}:\n",
       " -1.52029+0.0im            0.0+0.0im       …          0.0+0.0im\n",
       "      0.0+0.0im       -1.52029+0.0im              -0.9071-2.25361im\n",
       "  0.80802+0.244223im       0.0+0.0im                  0.0+0.0im\n",
       "      0.0+0.0im        0.80802+0.244223im       -0.206876+0.0342209im\n",
       " 0.597122-0.186586im       0.0+0.0im                  0.0+0.0im\n",
       "      0.0+0.0im       0.597122-0.186586im  …     0.778068+2.58633im\n",
       " 0.691343+0.124663im       0.0+0.0im                  0.0+0.0im\n",
       "      0.0+0.0im       0.691343+0.124663im       -0.668239+1.86129im\n",
       "  1.57398-0.658289im       0.0+0.0im                  0.0+0.0im\n",
       "      0.0+0.0im        1.57398-0.658289im        -1.37753-0.72592im\n",
       " 0.489922-0.32962im        0.0+0.0im       …          0.0+0.0im\n",
       "      0.0+0.0im       0.489922-0.32962im        -0.415608+1.79892im\n",
       " -1.74581-0.426855im       0.0+0.0im                  0.0+0.0im\n",
       "      0.0+0.0im       -1.74581-0.426855im     -0.00550296-2.7916im\n",
       "  -0.9071+2.25361im        0.0+0.0im                  0.0+0.0im\n",
       "      0.0+0.0im        -0.9071+2.25361im   …     0.783931+0.0im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaleatMat1 = rand(2,63).*2 .-1\n",
    "\n",
    "\n",
    "A1P = zeros(2^particles, 2^particles)\n",
    "for k in 1:length(ArrayA1)\n",
    "        A1P += xaleatMat1[1, k] * kron([Sigma[ArrayA1[k][j]] for j in eachindex(ArrayA1[1])]...)\n",
    "end\n",
    "A1P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16×16 Matrix{ComplexF64}:\n",
       "   0.52151+0.0im            -1.31201+1.33697im   …        0.0+0.0im\n",
       "  -1.31201-1.33697im         3.35943+0.0im                0.0+0.0im\n",
       "    1.7011-1.22411im     -0.00196794-2.06763im            0.0+0.0im\n",
       " -0.550764+0.00983804im     -1.17908-0.358467im           0.0+0.0im\n",
       " -0.280127-1.09387im         2.71802-1.41239im            0.0+0.0im\n",
       "  0.235618+0.692372im        1.19704-0.394437im  …        0.0+0.0im\n",
       " -0.178645-0.177204im       -0.95195+0.905777im           0.0+0.0im\n",
       "   1.03032+2.24106im       -0.729043-0.389587im           0.0+0.0im\n",
       "       0.0+0.0im                 0.0+0.0im            1.03032-2.24106im\n",
       "       0.0+0.0im                 0.0+0.0im          -0.729043+0.389587im\n",
       "       0.0+0.0im                 0.0+0.0im       …  -0.837036-1.02657im\n",
       "       0.0+0.0im                 0.0+0.0im           -2.36802-0.72506im\n",
       "       0.0+0.0im                 0.0+0.0im            0.26734-0.193219im\n",
       "       0.0+0.0im                 0.0+0.0im           -1.11962-1.83996im\n",
       "       0.0+0.0im                 0.0+0.0im           0.535556-1.43619im\n",
       "       0.0+0.0im                 0.0+0.0im       …  -0.344574+0.0im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A2P = zeros(2^particles, 2^particles)\n",
    "for k in 1:length(ArrayA2)\n",
    "        A2P += xaleatMat1[2, k] * kron([Sigma[ArrayA2[k][j]] for j in eachindex(ArrayA2[1])]...)\n",
    "end\n",
    "A2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda lo que haremos es generar un vector de tuplas con la información (x,y) donde x es un vector   \n",
    "# que contiene los promedios a1 y a2 con el estado 0,1,2,... después el vector y tendrá los valores c1 y c2 \n",
    "# estos valores se repetirán para todos los estados y promedios que consideramos del mismo Hamiltoniano, \n",
    "# es decir, si tenemos 4 estados y 2 promedio por estado, se repetirán 4 veces lso valores de y: c1 y c2\n",
    "# Tomamos para x la mitad de los estados del sistema\n",
    "\n",
    "c = rand(2,1000)*2 .-1 # Estos son los valores de y, los que queremos predecir, cada columna es un valor de y (contiene dos elementos)\n",
    "\n",
    "n = 1000 # Número de datos que queremos generar \n",
    "\n",
    "# Inicializamos un vector vacío para almacenar las 1000 tuplas \n",
    "Tup = []\n",
    "\n",
    "for k in 1 : n\n",
    "\n",
    "    mat1a1 = zeros(2) # Colocamos un vector de ceros que se va a reiniciar en cada paso \n",
    "\n",
    "    # Formamos el Hamiltoniano\n",
    "    H12 = c[1,k]*A1P + c[2,k]*A2P\n",
    "\n",
    "    # Tomamos los vectores propios \n",
    "\n",
    "    vor  = eigen(H12).vectors\n",
    "    adjvor = adjoint(vor)\n",
    "\n",
    "    vor[:,1] # Este es el primer vector propio, los vectores propios con eigen se colocan en columnas \n",
    "    adjvor[1,:] # Este es el primer vector propio para la adjunta (Recordemos es un vector izquierdo [Fila])\n",
    "\n",
    "    # Calculamos el valor esperado de la primera mitad de vectores propios\n",
    "\n",
    "    ExpValA = zeros(ComplexF64, Int((size(vor)[1])/2))\n",
    "    for i in 1:Int((size(vor)[1])/2)\n",
    "        ExpValA[i] = transpose(adjvor[i,:])*A1P*vor[:,i]\n",
    "    end\n",
    "\n",
    "    ExpValB = zeros(ComplexF64,Int((size(vor)[1])/2))  # ExpVal2[1] = a21 = \\bra{\\phi1_}A_2\\ket{\\phi_1}\n",
    "    for i in 1:Int((size(vor)[1])/2)\n",
    "        ExpValB[i] = transpose(adjvor[i,:])*A2P*vor[:,i]\n",
    "    end\n",
    "\n",
    "    ValsA = real(ExpValA) # Nos interesa únicamente la parte real, la parte imaginaria suele ser error \n",
    "    ValsB = real(ExpValB)\n",
    "    mat1a1[1] = ValsA[1]\n",
    "    mat1a1[2] = ValsB[1]\n",
    "\n",
    "    \n",
    "\n",
    "    tk = (mat1a1, c[:,k]) # Generamos una tupla con un vector que tiene 2 promedios y un vector con c1 y c2 para el respectivo Hamiltoniano\n",
    "    push!(Tup,tk) # Agregar la tupla al vector \n",
    "\n",
    "    ValsCompleto = vcat(ValsA, ValsB) # Por último nuestro vector tendrá la forma de 8x1, para poder agregarlo al batch \n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadata (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loadata(batchsize, train_split)\n",
    "    # Separar la tupla anterior en los dos batches de datos, los elementos de x y los de y. \n",
    "\n",
    "    # Extract inputs (x) and outputs (y) from the tuples\n",
    "    x_batch = cat(map(t -> t[1], Tup)...; dims=2)  # Stack inputs along the 4th dimension (batch)\n",
    "    y_batch = cat(map(t -> t[2], Tup)...; dims=2)  # Stack outputs along the 2nd dimension (batch)\n",
    "    (x_train, y_train), (x_test, y_test) = splitobs((x_batch, y_batch); at=train_split) # Separa los datos en train y test\n",
    "\n",
    "    return (\n",
    "        # Use DataLoader to automatically minibatch and shuffle the data\n",
    "        DataLoader(collect.((x_train, y_train)); batchsize, shuffle=true, partial=false),\n",
    "        # Don't shuffle the test data\n",
    "        DataLoader(collect.((x_test, y_test)); batchsize, shuffle=false, partial=false),\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "    layer_1 = Dense(2 => 64),           \u001b[90m# 192 parameters\u001b[39m\n",
       "    layer_2 = Dense(64 => 32, myleakyrelu),  \u001b[90m# 2_080 parameters\u001b[39m\n",
       "    layer_3 = Dense(32 => 2),           \u001b[90m# 66 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: \u001b[39m2_338 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myleakyrelu(x) = leakyrelu(x,0.1)\n",
    "\n",
    "model = Chain(\n",
    "    Dense(2,64),\n",
    "    Dense(64,32,myleakyrelu),\n",
    "    Dense(32,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_fn (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CosineSimilarity(x,y) = sum(x.*y)/sqrt(sum(x.^2)*sum(y.^2)) # x, y no son los mismos que los del modelo\n",
    "function myloss(x,y)\n",
    "    return 1 - CosineSimilarity(x,y)\n",
    "end\n",
    "\n",
    "function loss_fn(model,ps,st,d)\n",
    "    x,y = d\n",
    "    ŷ,stn = model(x,ps,st)\n",
    "\n",
    "    return myloss(ŷ,y),stn,(;)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleChainsLayer(\n",
       "    Chain(\n",
       "        layer_1 = Dense(2 => 64),       \u001b[90m# 192 parameters\u001b[39m\n",
       "        layer_2 = Dense(64 => 32, myleakyrelu),  \u001b[90m# 2_080 parameters\u001b[39m\n",
       "        layer_3 = Dense(32 => 2),       \u001b[90m# 66 parameters\u001b[39m\n",
       "    ),\n",
       ") \u001b[90m        # Total: \u001b[39m2_338 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adaptor = ToSimpleChainsAdaptor((2,))  # forma de entrada\n",
    "simple_chains_model = adaptor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const lossfn = loss_fn \n",
    "\n",
    "# CrossEntropyLoss(; logits=Val(true)) # const se usa para decirle a Julia que el tipo de la variable global no va a cambiar: https://docs.julialang.org/en/v1/base/base/#const\n",
    "function accuracy(model, ps, st, dataloader)\n",
    "    total_correct, total = 0, 0\n",
    "    st = Lux.testmode(st) # Se configura el modelo para hacer inferencia.\n",
    "    for (x, y) in dataloader\n",
    "        target_class = onecold(Array(y)) # Es tomar el elemento con mayor probabilidad. Equivalentemente es softmax con temperature cero.\n",
    "        predicted_class = onecold(Array(first(model(x, ps, st)))) # Es tomar el elemento con mayor probabilidad. Equivalentemente es softmax con temperature cero.\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:eta, :beta, :epsilon)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fieldnames(Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function train(model, dev=cpu_device(); rng=Random.default_rng(), kwargs...)\n",
    "    train_dataloader, test_dataloader = dev(loadata(100, 0.9))\n",
    "    ps, st = dev(Lux.setup(rng, model)) # se inicializan los parámetros del modelo de forma aleatoria y se cargan en el CPU (dev)\n",
    "\n",
    "    vjp = dev isa ReactantDevice ? AutoEnzyme() : AutoZygote() # Usando Reactant permite compilar el modelo antes de entrenarlo: https://lux.csail.mit.edu/stable/manual/compiling_lux_models#reactant-compilation\n",
    "\n",
    "    train_state = Training.TrainState(model, ps, st, Adam(3.0f-4)) \n",
    "\n",
    "    if dev isa ReactantDevice\n",
    "        x_ra = first(test_dataloader)[1]\n",
    "        model_compiled = @compile model(x_ra, ps, Lux.testmode(st)) # Justo aquí es compilado el modelo\n",
    "    else\n",
    "        model_compiled = model\n",
    "    end\n",
    "\n",
    "    ### Lets train the model\n",
    "    nepochs = 10 # Cuantas veces se pasa por todos los datos\n",
    "    tr_acc, te_acc = 0.0, 0.0 # Se inicializan las variables de accuracy\n",
    "    for epoch in 1:nepochs\n",
    "        stime = time()\n",
    "        for (x, y) in train_dataloader # Dos preguntas: x y y ya son arreglos o son otro objeto? y en cada evaluación se reordenan?\n",
    "            _, _, _, train_state = Training.single_train_step!(\n",
    "                vjp, lossfn, (x, y), train_state\n",
    "            )\n",
    "        end\n",
    "        ttime = time() - stime\n",
    "\n",
    "        tr_acc =\n",
    "            accuracy(\n",
    "                model_compiled, train_state.parameters, train_state.states, train_dataloader\n",
    "            ) * 100\n",
    "        te_acc =\n",
    "            accuracy(\n",
    "                model_compiled, train_state.parameters, train_state.states, test_dataloader\n",
    "            ) * 100\n",
    "\n",
    "        @printf \"[%2d/%2d] \\t Time %.2fs \\t Training Accuracy: %.2f%% \\t Test Accuracy: \\\n",
    "                 %.2f%%\\n\" epoch nepochs ttime tr_acc te_acc\n",
    "    end\n",
    "\n",
    "    return train_state.parameters, train_state.states, tr_acc, te_acc # En el código del tutorial no están las primeras dos variables, lo modifiqué para que nos devuelva los parámetros entrenados.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] \t Time 85.14s \t Training Accuracy: 87.44% \t Test Accuracy: 85.00%\n",
      "[ 2/10] \t Time 0.00s \t Training Accuracy: 90.22% \t Test Accuracy: 91.00%\n",
      "[ 3/10] \t Time 0.00s \t Training Accuracy: 92.78% \t Test Accuracy: 93.00%\n",
      "[ 4/10] \t Time 0.00s \t Training Accuracy: 93.44% \t Test Accuracy: 95.00%\n",
      "[ 5/10] \t Time 0.00s \t Training Accuracy: 93.33% \t Test Accuracy: 94.00%\n",
      "[ 6/10] \t Time 0.00s \t Training Accuracy: 92.33% \t Test Accuracy: 93.00%\n",
      "[ 7/10] \t Time 0.00s \t Training Accuracy: 92.22% \t Test Accuracy: 93.00%\n",
      "[ 8/10] \t Time 0.00s \t Training Accuracy: 93.44% \t Test Accuracy: 93.00%\n",
      "[ 9/10] \t Time 0.00s \t Training Accuracy: 94.33% \t Test Accuracy: 95.00%\n",
      "[10/10] \t Time 0.00s \t Training Accuracy: 95.22% \t Test Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "tr_acc, te_acc = train(model, reactant_device()); # entrenando el modelo en lux, este tarda más "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] \t Time 33.16s \t Training Accuracy: 43.56% \t Test Accuracy: 46.00%\n",
      "[ 2/10] \t Time 0.00s \t Training Accuracy: 47.33% \t Test Accuracy: 48.00%\n",
      "[ 3/10] \t Time 0.00s \t Training Accuracy: 70.11% \t Test Accuracy: 72.00%\n",
      "[ 4/10] \t Time 0.00s \t Training Accuracy: 88.67% \t Test Accuracy: 89.00%\n",
      "[ 5/10] \t Time 0.00s \t Training Accuracy: 89.00% \t Test Accuracy: 88.00%\n",
      "[ 6/10] \t Time 0.00s \t Training Accuracy: 90.56% \t Test Accuracy: 89.00%\n",
      "[ 7/10] \t Time 0.00s \t Training Accuracy: 92.00% \t Test Accuracy: 89.00%\n",
      "[ 8/10] \t Time 0.00s \t Training Accuracy: 94.22% \t Test Accuracy: 93.00%\n",
      "[ 9/10] \t Time 0.00s \t Training Accuracy: 95.44% \t Test Accuracy: 95.00%\n",
      "[10/10] \t Time 0.00s \t Training Accuracy: 96.67% \t Test Accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "ps, st, tr_acc, te_acc = train(simple_chains_model); #entrenando el modelo de simple simple_chains_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
